{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from contextlib import nullcontext\n",
    "import torch\n",
    "import tiktoken\n",
    "from model import GPTConfig, GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "init_from = 'resume' # either 'resume' (from an out_dir) or a gpt2 variant (e.g. 'gpt2-xl')\n",
    "out_dir = 'out' # ignored if init_from is not 'resume'\n",
    "start = \"\\n\" # or \"<|endoftext|>\" or etc. Can also specify a file, use as: \"FILE:prompt.txt\"\n",
    "num_samples = 10 # number of samples to draw\n",
    "max_new_tokens = 500 # number of tokens generated in each sample\n",
    "temperature = 0.8 # 1.0 = no change, < 1.0 = less random, > 1.0 = more random, in predictions\n",
    "top_k = 200 # retain only the top_k most likely tokens, clamp others to have 0 probability\n",
    "seed = 1337\n",
    "device = 'cuda' # examples: 'cpu', 'cuda', 'cuda:0', 'cuda:1', etc.\n",
    "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32' or 'bfloat16' or 'float16'\n",
    "compile = False # use PyTorch 2.0 to compile the model to be faster\n",
    "open('/data1/zhengnanyan/myNanoGPT/configurator.py').read()# overrides from command line or config file\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\n",
    "torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n",
    "device_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 85.00M\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "if init_from == 'resume':\n",
    "    # init from a model saved in a specific directory\n",
    "    ckpt_path = os.path.join(out_dir, 'ckpt.pt')\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    gptconf = GPTConfig(**checkpoint['model_args'])\n",
    "    model = GPT(gptconf)\n",
    "    state_dict = checkpoint['model']\n",
    "    unwanted_prefix = '_orig_mod.'\n",
    "    for k,v in list(state_dict.items()):\n",
    "        if k.startswith(unwanted_prefix):\n",
    "            state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "    model.load_state_dict(state_dict)\n",
    "elif init_from.startswith('gpt2'):\n",
    "    # init from a given GPT-2 model\n",
    "    model = GPT.from_pretrained(init_from, dict(dropout=0.0))\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "if compile:\n",
    "    model = torch.compile(model) # requires PyTorch 2.0 (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(65, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (ln_1): LayerNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (c_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=65, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading meta from data/meta.pkl...\n"
     ]
    }
   ],
   "source": [
    "# look for the meta pickle in case it is available in the dataset folder\n",
    "load_meta = False\n",
    "if init_from == 'resume' and 'config' in checkpoint and 'dataset' in checkpoint['config']: # older checkpoints might not have these...\n",
    "    # meta_path = os.path.join('data', checkpoint['config']['dataset'], 'meta.pkl')\n",
    "    meta_path = os.path.join('data', 'meta.pkl')\n",
    "    load_meta = os.path.exists(meta_path)\n",
    "if load_meta:\n",
    "    print(f\"Loading meta from {meta_path}...\")\n",
    "    with open(meta_path, 'rb') as f:\n",
    "        meta = pickle.load(f)\n",
    "    # TODO want to make this more general to arbitrary encoder/decoder schemes\n",
    "    stoi, itos = meta['stoi'], meta['itos']\n",
    "    encode = lambda s: [stoi[c] for c in s]\n",
    "    decode = lambda l: ''.join([itos[i] for i in l])\n",
    "else:\n",
    "    # ok let's assume gpt-2 encodings by default\n",
    "    print(\"No meta.pkl found, assuming GPT-2 encodings...\")\n",
    "    enc = tiktoken.get_encoding(\"gpt2\")\n",
    "    encode = lambda s: enc.encode(s, allowed_special={\"<|endoftext|>\"})\n",
    "    decode = lambda l: enc.decode(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/meta.pkl'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_path = os.path.join('data','meta.pkl')\n",
    "meta_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 65,\n",
       " 'itos': {0: '\\n',\n",
       "  1: ' ',\n",
       "  2: '!',\n",
       "  3: '$',\n",
       "  4: '&',\n",
       "  5: \"'\",\n",
       "  6: ',',\n",
       "  7: '-',\n",
       "  8: '.',\n",
       "  9: '3',\n",
       "  10: ':',\n",
       "  11: ';',\n",
       "  12: '?',\n",
       "  13: 'A',\n",
       "  14: 'B',\n",
       "  15: 'C',\n",
       "  16: 'D',\n",
       "  17: 'E',\n",
       "  18: 'F',\n",
       "  19: 'G',\n",
       "  20: 'H',\n",
       "  21: 'I',\n",
       "  22: 'J',\n",
       "  23: 'K',\n",
       "  24: 'L',\n",
       "  25: 'M',\n",
       "  26: 'N',\n",
       "  27: 'O',\n",
       "  28: 'P',\n",
       "  29: 'Q',\n",
       "  30: 'R',\n",
       "  31: 'S',\n",
       "  32: 'T',\n",
       "  33: 'U',\n",
       "  34: 'V',\n",
       "  35: 'W',\n",
       "  36: 'X',\n",
       "  37: 'Y',\n",
       "  38: 'Z',\n",
       "  39: 'a',\n",
       "  40: 'b',\n",
       "  41: 'c',\n",
       "  42: 'd',\n",
       "  43: 'e',\n",
       "  44: 'f',\n",
       "  45: 'g',\n",
       "  46: 'h',\n",
       "  47: 'i',\n",
       "  48: 'j',\n",
       "  49: 'k',\n",
       "  50: 'l',\n",
       "  51: 'm',\n",
       "  52: 'n',\n",
       "  53: 'o',\n",
       "  54: 'p',\n",
       "  55: 'q',\n",
       "  56: 'r',\n",
       "  57: 's',\n",
       "  58: 't',\n",
       "  59: 'u',\n",
       "  60: 'v',\n",
       "  61: 'w',\n",
       "  62: 'x',\n",
       "  63: 'y',\n",
       "  64: 'z'},\n",
       " 'stoi': {'\\n': 0,\n",
       "  ' ': 1,\n",
       "  '!': 2,\n",
       "  '$': 3,\n",
       "  '&': 4,\n",
       "  \"'\": 5,\n",
       "  ',': 6,\n",
       "  '-': 7,\n",
       "  '.': 8,\n",
       "  '3': 9,\n",
       "  ':': 10,\n",
       "  ';': 11,\n",
       "  '?': 12,\n",
       "  'A': 13,\n",
       "  'B': 14,\n",
       "  'C': 15,\n",
       "  'D': 16,\n",
       "  'E': 17,\n",
       "  'F': 18,\n",
       "  'G': 19,\n",
       "  'H': 20,\n",
       "  'I': 21,\n",
       "  'J': 22,\n",
       "  'K': 23,\n",
       "  'L': 24,\n",
       "  'M': 25,\n",
       "  'N': 26,\n",
       "  'O': 27,\n",
       "  'P': 28,\n",
       "  'Q': 29,\n",
       "  'R': 30,\n",
       "  'S': 31,\n",
       "  'T': 32,\n",
       "  'U': 33,\n",
       "  'V': 34,\n",
       "  'W': 35,\n",
       "  'X': 36,\n",
       "  'Y': 37,\n",
       "  'Z': 38,\n",
       "  'a': 39,\n",
       "  'b': 40,\n",
       "  'c': 41,\n",
       "  'd': 42,\n",
       "  'e': 43,\n",
       "  'f': 44,\n",
       "  'g': 45,\n",
       "  'h': 46,\n",
       "  'i': 47,\n",
       "  'j': 48,\n",
       "  'k': 49,\n",
       "  'l': 50,\n",
       "  'm': 51,\n",
       "  'n': 52,\n",
       "  'o': 53,\n",
       "  'p': 54,\n",
       "  'q': 55,\n",
       "  'r': 56,\n",
       "  's': 57,\n",
       "  't': 58,\n",
       "  'u': 59,\n",
       "  'v': 60,\n",
       "  'w': 61,\n",
       "  'x': 62,\n",
       "  'y': 63,\n",
       "  'z': 64}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(meta_path, 'rb') as f:\n",
    "    meta = pickle.load(f)\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the beginning of the prompt\n",
    "if start.startswith('FILE:'):\n",
    "    with open(start[5:], 'r', encoding='utf-8') as f:\n",
    "        start = f.read()\n",
    "start_ids = encode(start)\n",
    "x = (torch.tensor(start_ids, dtype=torch.long, device=device)[None, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0]], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ANGELO:\n",
      "And cown, which you trade to your do:\n",
      "You remember to answer? What I will you back:\n",
      "It was, away, my father?\n",
      "\n",
      "ISABELLA:\n",
      "It pray you heart mildnedly, beg it endeed,\n",
      "A late maid overture.\n",
      "\n",
      "ANGELO:\n",
      "Well, by self you tear.\n",
      "\n",
      "ISABELLA:\n",
      "I with that speak you love.\n",
      "I cannot sign so doth the little leonWeed!\n",
      "For Cominget, and do rive with you strong of his?\n",
      "\n",
      "ANGELO:\n",
      "On this from; I know not with all often affect?\n",
      "\n",
      "ISABELLA:\n",
      "I see!\n",
      "\n",
      "ANGELO:\n",
      "\n",
      ":\n",
      "Is do, no gentleman.\n",
      "\n",
      "ISABELLA:\n",
      "So remember your lord\n",
      "---------------\n",
      "\n",
      "Menenty to my graventy.\n",
      "\n",
      "BUCKINGHAM:\n",
      "Belingbroke, my lord, therefore words to me the well.\n",
      "I, why, come sometisfaction, my lordship me?\n",
      "Some more I desire moved to dissected on true?\n",
      "\n",
      "MONTAGUE:\n",
      "Dest so, my Richard: there's noblest is good dead?\n",
      "\n",
      "BRAPT:\n",
      "I charge bear that me virtue an so leved upon\n",
      "For these lady of Gloucester, I say it his kind.\n",
      "\n",
      "KING RICHARD II:\n",
      "Sever it is is out ornishmen subjects,\n",
      "But on what that the ruins Englishbam,\n",
      "That he set part of watch time worthir face;\n",
      "To know our\n",
      "---------------\n",
      "\n",
      "Merrond: it we say sir, I would were her the\n",
      "To the princess; I am not were should meet meet thinks\n",
      "Of tears times, in the huggest of would was\n",
      "The brokened his foI have a cannot to makes.\n",
      "Look me knew me, my lord, but weep-good men\n",
      "The shall earth. Come, gentle and my heart to much.\n",
      "Who she, my lord, what I'll friend the hast,\n",
      "Shall I break not man.\n",
      "\n",
      "SICINIUS:\n",
      "We think they sing the been defending but fines,\n",
      "My love banish of my poor and and omb,\n",
      "And tender them graves of their stars,\n",
      "And hate \n",
      "---------------\n",
      "\n",
      "Think will king with them rans, and I find\n",
      "The loo--\n",
      "\n",
      "Second Citizen:\n",
      "A sine the day with the son of Bolingbroke:\n",
      "And there were the country deserve rid.\n",
      "\n",
      "First Citizen:\n",
      "Sir, and thou man's when as to be, this sent; and\n",
      "when I'll not wife it before the world, thou water.\n",
      "The livoute thee worthy the woman in a gate.\n",
      "\n",
      "First Citizen:\n",
      "Your like he honour with with him words: why will say,\n",
      "thy proud him dismins and with all and will one stone\n",
      "and the brids shown'd for them, but whom nothing.\n",
      "\n",
      "Second \n",
      "---------------\n",
      "\n",
      "Be ever but were, her looks of fellow.\n",
      "\n",
      "JULIET:\n",
      "I may gone fast the dead me to thee.\n",
      "\n",
      "Nurse:\n",
      "And do you to offend I'll to thee love,\n",
      "Ten then, and else, for you swear mine shall.\n",
      "\n",
      "JULIET:\n",
      "I do man that I shall be not with upon thee.\n",
      "\n",
      "Nurse:\n",
      "I have been not my son'd that I may be the matte?\n",
      "\n",
      "JULIET:\n",
      "Adieu! man, by in no appreased ill.\n",
      "\n",
      "Nurse:\n",
      "O, sir, my lord, madam! say, the should be so here!\n",
      "\n",
      "Nurse:\n",
      "Sings I, one should bold be a the death:\n",
      "If it the book of men follow next\n",
      "As soldier than seem \n",
      "---------------\n",
      "\n",
      "\n",
      "MERCUTIO:\n",
      "Have brave standers thou, the grace trulhest away\n",
      "And the prison virtue, but an windess amend adm;\n",
      "Who art thou heart than rough a suppected\n",
      "When and slang for our pastion.\n",
      "\n",
      "ROMEO:\n",
      "I will it is near; there's in were with die,\n",
      "That king kinsman me she line appliare.\n",
      "\n",
      "MERCUTIO:\n",
      "Ay, and on was her father a citizens again!\n",
      "Time her a time win a look of enproace,\n",
      "Which be would shame with store than lettern breasts,\n",
      "And that send vows the secord maid, and thereon,\n",
      "But strike with world's t\n",
      "---------------\n",
      "\n",
      "Shall the been him blow, and fiery shall,\n",
      "And I have not to Ross Apil an all thee.\n",
      "For thee shall thee affehering their stands.\n",
      "\n",
      "KING EDWARD IV:\n",
      "Canst throw thou deadler of Buckingham age.\n",
      "\n",
      "HAnry STIRENord of Sentence of my wrongs.\n",
      "\n",
      "KING HENRY VI:\n",
      "My lords, by Warwick, and may sound\n",
      "Well was it the fly the stronger and men.\n",
      "\n",
      "WARWICK:\n",
      "Therefore, and am sorrowed England will to greet,\n",
      "And then chyild Henry a foot, and fearby.\n",
      "\n",
      "KING HENRY VI:\n",
      "I have the careful Fxpair before Ireland.\n",
      "\n",
      "WARWICK:\n",
      "Ay d\n",
      "---------------\n",
      "\n",
      "lay behold framous nature, or proven sake,\n",
      "Angelo the bestance the king, to orander the king.\n",
      "\n",
      "PRINCE EDWARD:\n",
      "Say, my learn great all in best the will.\n",
      "\n",
      "GLOUCESTER:\n",
      "I durpose to me to all of this offence.\n",
      "\n",
      "QUEEN MARGARET:\n",
      "That show shall I come stooth of Welshming stand.\n",
      "\n",
      "PRINCE EDWARD:\n",
      "Where do our we shaquest our dead!\n",
      "Against the vantage of my eyes,\n",
      "And changed of Phoeming makes of Lancaster,\n",
      "And deminer and once with fields the Slain.\n",
      "\n",
      "CLARENCE:\n",
      "Alack, but England, the very with Lord Henry C\n",
      "---------------\n",
      "\n",
      "\n",
      "LEONTES:\n",
      "The read past, no seem inform, and them like,\n",
      "And in of thine shall seems on't aidy sole,\n",
      "Of Romeo make of Dial of Banina soldies\n",
      "To Appeleness love in thy brother's honours!\n",
      "\n",
      "First Lont's of Exen dead, Charge, is false,\n",
      "In restrenger than he wice come hath been heart.\n",
      "\n",
      "AUTOLYCUS:\n",
      "In then that in no him and man's doth as he\n",
      "To have bear there sunserves and this is grief,\n",
      "And all the hearts she ones of his sour.\n",
      "\n",
      "Clown:\n",
      "Cheriss it hath have say cursed at throats dry\n",
      "seen and his be was \n",
      "---------------\n",
      "\n",
      "Hourd do his rathred have himself hands:\n",
      "And I have he was him deabled fly mine.\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "Come, sir?\n",
      "\n",
      "NORTHUMBERLAND:\n",
      "There's the sets'd marks propheenss a ways,\n",
      "He hath red Henry soreut the cause woe,\n",
      "Now one a brought root, findly your shade.\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "My lord, my lord upon that I drown to place.\n",
      "\n",
      "DUKE OF YORK:\n",
      "By 'twas you doth tender are great you.\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "My my gracious lords, what it in degren,\n",
      "But charition as to Hastingstions presence,\n",
      "Or order into my re\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# run generation\n",
    "with torch.no_grad():\n",
    "    with ctx:\n",
    "        for k in range(num_samples):\n",
    "            y = model.generate(x, max_new_tokens, temperature=temperature, top_k=top_k)\n",
    "            print(decode(y[0].tolist()))\n",
    "            print('---------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanoGPT39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
